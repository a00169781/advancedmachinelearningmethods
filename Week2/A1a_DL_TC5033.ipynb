{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 1a: Implementing a Multilayer Fully Connected Network using Numpy\n",
    "#### Non-graded activity (0 points)\n",
    "\n",
    "- Objective\n",
    "\n",
    "The primary objective of this activity is to deepen your understanding of Fully Connected Networks by implementing a multilayer network using only Numpy. You  are  given  the follosing starter code that solves the MNIST dataset problem. Your task is to read, understand, and then apply this knowledge to solve classification problems on other datasets such as the Kaggle ASL dataset (Starter code will be provided separately for that activity).\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    Read and Understand the following Code: The provided starter code outlines the architecture of a Fully Connected Network designed to classify MNIST images. Go through the code to understand how each function and class is used to implement the network.\n",
    "\n",
    "    Understand the Math: Make sure you understand the math operations implemented in the code, especially during the forward and backward passes. This will involve matrix multiplications, activation functions, loss computations, and backpropagation.\n",
    "    \n",
    "- Experiment\n",
    "    You are encouraged to play with the code, change any hyperparameters and train the model, you should be able to achieve over 95% accuracy on the test set without problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num[0]\n",
    "l = x_train_num.reshape(x_train_num.shape[0], -1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,\n",
       "        18.,  18., 126., 136., 175.,  26., 166., 255., 247., 127.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        30.,  36.,  94., 154., 170., 253., 253., 253., 253., 253., 225.,\n",
       "       172., 253., 242., 195.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        18., 219., 253., 253., 253., 253., 253., 198., 182., 247., 241.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n",
       "       253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  11., 190., 253.,  70.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240.,\n",
       "       253., 253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  16.,  93., 252., 253., 187.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 249., 253.,\n",
       "       249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253.,\n",
       "       250., 182.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24., 114.,\n",
       "       221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  23.,  66., 213., 253., 253., 253., 253., 198.,  81.,\n",
       "         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "       253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  55.,\n",
       "       172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135.,\n",
       "       132.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(33.39512885204082), np.float64(78.6661972212754), np.float64(0.0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-9.646705203355238e-18), np.float64(0.9999999999999997))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0])\n",
    "b = a.view(np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.np_tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np_tensor([ True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(x, y, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 512\n",
    "learning_rate = 1e-4\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo: 0.30292505576982515, accuracy: 0.9197\n",
      "costo: 0.18401958405763832, accuracy: 0.9387\n",
      "costo: 0.15957866197591372, accuracy: 0.947\n",
      "costo: 0.1947867913277377, accuracy: 0.9516\n",
      "costo: 0.14577821139296063, accuracy: 0.9578\n",
      "costo: 0.1841810291594034, accuracy: 0.9594\n",
      "costo: 0.17923918947269413, accuracy: 0.9625\n",
      "costo: 0.06744985622902525, accuracy: 0.9647\n",
      "costo: 0.08161132963009206, accuracy: 0.9644\n",
      "costo: 0.08160065511154128, accuracy: 0.9655\n",
      "costo: 0.11927710257960931, accuracy: 0.9655\n",
      "costo: 0.07537333468456354, accuracy: 0.9663\n",
      "costo: 0.08820346701168898, accuracy: 0.9664\n",
      "costo: 0.1009322245739462, accuracy: 0.968\n",
      "costo: 0.051680786800371484, accuracy: 0.9683\n",
      "costo: 0.03204290495245267, accuracy: 0.9687\n",
      "costo: 0.0622926525937067, accuracy: 0.9706\n",
      "costo: 0.05866247228813196, accuracy: 0.9704\n",
      "costo: 0.0682515850356515, accuracy: 0.9708\n",
      "costo: 0.06117069010029593, accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho es: 2, el valor real es:2\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
